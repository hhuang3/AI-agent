{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPkN4yagY0WydjgxD0zT5eh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"SljbnxUyyZv1"},"outputs":[],"source":["import os\n","import re\n","from abc import ABC, abstractmethod\n","\n","from camel.agents import RolePlaying\n","from camel.messages import ChatMessage\n","from camel.typing import TaskType, ModelType\n","from chatdev.chat_env import ChatEnv\n","from chatdev.statistics import get_info\n","from chatdev.utils import log_visualize, log_arguments\n","\n","\n"]},{"cell_type":"code","source":["class Phase(ABC):\n","\n","    def __init__(self,\n","                 assistant_role_name,\n","                 user_role_name,\n","                 phase_prompt,\n","                 role_prompts,\n","                 phase_name,\n","                 model_type,\n","                 log_filepath):\n","\n","\n","        self.seminar_conclusion = None\n","        self.assistant_role_name = assistant_role_name\n","        self.user_role_name = user_role_name\n","        self.phase_prompt = phase_prompt\n","        self.phase_env = dict()\n","        self.phase_name = phase_name\n","        self.assistant_role_prompt = role_prompts[assistant_role_name]\n","        self.user_role_prompt = role_prompts[user_role_name]\n","        self.ceo_prompt = role_prompts[\"Chief Executive Officer\"]\n","        self.counselor_prompt = role_prompts[\"Counselor\"]\n","        self.max_retries = 3\n","        self.reflection_prompt = \"\"\"Here is a conversation between two roles: {conversations} {question}\"\"\"\n","        self.model_type = model_type\n","        self.log_filepath = log_filepath\n","\n","    @log_arguments\n","    def chatting(\n","            self,\n","            chat_env,\n","            task_prompt: str,\n","            assistant_role_name: str,\n","            user_role_name: str,\n","            phase_prompt: str,\n","            phase_name: str,\n","            assistant_role_prompt: str,\n","            user_role_prompt: str,\n","            task_type=TaskType.CHATDEV,\n","            need_reflect=False,\n","            with_task_specify=False,\n","            model_type=ModelType.GPT_3_5_TURBO,\n","            memory=None,\n","            placeholders=None,\n","            chat_turn_limit=10\n","    ) -> str:\n","\n","\n","\n","\n","        if placeholders is None:\n","            placeholders = {}\n","        assert 1 <= chat_turn_limit <= 100\n","\n","        if not chat_env.exist_employee(assistant_role_name):\n","            raise ValueError(f\"{assistant_role_name} not recruited in ChatEnv.\")\n","        if not chat_env.exist_employee(user_role_name):\n","            raise ValueError(f\"{user_role_name} not recruited in ChatEnv.\")\n","\n","        # init role play\n","        role_play_session = RolePlaying(\n","            assistant_role_name=assistant_role_name,\n","            user_role_name=user_role_name,\n","            assistant_role_prompt=assistant_role_prompt,\n","            user_role_prompt=user_role_prompt,\n","            task_prompt=task_prompt,\n","            task_type=task_type,\n","            with_task_specify=with_task_specify,\n","            memory=memory,\n","            model_type=model_type,\n","            background_prompt=chat_env.config.background_prompt\n","        )\n","\n","        # log_visualize(\"System\", role_play_session.assistant_sys_msg)\n","        # log_visualize(\"System\", role_play_session.user_sys_msg)\n","\n","        # start the chat\n","        _, input_user_msg = role_play_session.init_chat(None, placeholders, phase_prompt)\n","        seminar_conclusion = None\n","\n","\n","        for i in range(chat_turn_limit):\n","\n","            assistant_response, user_response = role_play_session.step(input_user_msg, chat_turn_limit == 1)\n","\n","            conversation_meta = \"**\" + assistant_role_name + \"<->\" + user_role_name + \" on : \" + str(\n","                phase_name) + \", turn \" + str(i) + \"**\\n\\n\"\n","\n","            # TODO: max_tokens_exceeded errors here\n","            if isinstance(assistant_response.msg, ChatMessage):\n","                # we log the second interaction here\n","                log_visualize(role_play_session.assistant_agent.role_name,\n","                              conversation_meta + \"[\" + role_play_session.user_agent.system_message.content + \"]\\n\\n\" + assistant_response.msg.content)\n","                if role_play_session.assistant_agent.info:\n","                    seminar_conclusion = assistant_response.msg.content\n","                    break\n","                if assistant_response.terminated:\n","                    break\n","\n","            if isinstance(user_response.msg, ChatMessage):\n","                # here is the result of the second interaction, which may be used to start the next chat turn\n","                log_visualize(role_play_session.user_agent.role_name,\n","                              conversation_meta + \"[\" + role_play_session.assistant_agent.system_message.content + \"]\\n\\n\" + user_response.msg.content)\n","                if role_play_session.user_agent.info:\n","                    seminar_conclusion = user_response.msg.content\n","                    break\n","                if user_response.terminated:\n","                    break\n","\n","            # continue the chat\n","            if chat_turn_limit > 1 and isinstance(user_response.msg, ChatMessage):\n","                input_user_msg = user_response.msg\n","            else:\n","                break\n","\n","        # conduct self reflection\n","        if need_reflect:\n","            if seminar_conclusion in [None, \"\"]:\n","                seminar_conclusion = \"<INFO> \" + self.self_reflection(task_prompt, role_play_session, phase_name,\n","                                                                      chat_env)\n","            if \"recruiting\" in phase_name:\n","                if \"Yes\".lower() not in seminar_conclusion.lower() and \"No\".lower() not in seminar_conclusion.lower():\n","                    seminar_conclusion = \"<INFO> \" + self.self_reflection(task_prompt, role_play_session,\n","                                                                          phase_name,\n","                                                                          chat_env)\n","            elif seminar_conclusion in [None, \"\"]:\n","                seminar_conclusion = \"<INFO> \" + self.self_reflection(task_prompt, role_play_session, phase_name,\n","                                                                      chat_env)\n","        else:\n","            seminar_conclusion = assistant_response.msg.content\n","\n","        log_visualize(\"**[Seminar Conclusion]**:\\n\\n {}\".format(seminar_conclusion))\n","        seminar_conclusion = seminar_conclusion.split(\"<INFO>\")[-1]\n","        return seminar_conclusion\n","\n","\n","    @abstractmethod\n","    def update_phase_env(self, chat_env):\n","        pass\n","\n","    @abstractmethod\n","    def update_chat_env(self, chat_env) -> ChatEnv:\n","\n","        pass\n","\n","    def execute(self, chat_env, chat_turn_limit, need_reflect) -> ChatEnv:\n","\n","        self.update_phase_env(chat_env)\n","        self.seminar_conclusion = \\\n","            self.chatting(chat_env=chat_env,\n","                          task_prompt=chat_env.env_dict['task_prompt'],\n","                          need_reflect=need_reflect,\n","                          assistant_role_name=self.assistant_role_name,\n","                          user_role_name=self.user_role_name,\n","                          phase_prompt=self.phase_prompt,\n","                          phase_name=self.phase_name,\n","                          assistant_role_prompt=self.assistant_role_prompt,\n","                          user_role_prompt=self.user_role_prompt,\n","                          chat_turn_limit=chat_turn_limit,\n","                          placeholders=self.phase_env,\n","                          memory=chat_env.memory,\n","                          model_type=self.model_type)\n","        chat_env = self.update_chat_env(chat_env)\n","        return chat_env\n"],"metadata":{"id":"9vf-Ei8yQx5A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DemandAnalysis():\n","  def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","  def update_phase_env(self, chat_env):\n","        pass\n","\n","  def update_chat_env(self, chat_env) -> ChatEnv:\n","        if len(self.seminar_conclusion) > 0:\n","            chat_env.env_dict['analysis'] = self.seminar_conclusion.split(\"<INFO>\")[-1].lower().replace(\".\", \"\").strip()\n","        return chat_env"],"metadata":{"id":"RsZMk655sGkU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FacultyDecision():\n","  def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","  def update_phase_env():\n","    self.phase_env.update({\"task\": chat_env.env_dict['task_prompt'],\n","                           \"description\": chat_env.env_dict['task_description'],\n","                           \"analysis\":chat_env.env_dict['analysis']})\n","\n","\n","  def update_chat_env():\n","        if len(self.seminar_conclusion) > 0:\n","            chat_env.env_dict['faculty'] = self.seminar_conclusion.split(\"<INFO>\")[-1].lower().replace(\".\", \"\").strip()\n","        return chat_env\n","\n"],"metadata":{"id":"l91HOEhusNL9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class StudentDecision():\n","  def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","  def update_phase_env():\n","    self.phase_env.update({\"task\": chat_env.env_dict['task_prompt'],\n","                           \"description\": chat_env.env_dict['task_description'],\n","                           \"analysis\": chat_env.env_dict['analysis'],\n","                           \"faculty\": chat_env.env_dict['faculty']})\n","\n","\n","\n","  def update_chat_env():\n","        if len(self.seminar_conclusion) > 0:\n","            chat_env.env_dict['student'] = self.seminar_conclusion.split(\"<INFO>\")[-1].lower().replace(\".\", \"\").strip()\n","        return chat_env"],"metadata":{"id":"1i8R9HFasQcU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DeanDecision():\n","  def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","  def update_phase_env():\n","    self.phase_env.update({\"task\": chat_env.env_dict['task_prompt'],\n","                           \"description\": chat_env.env_dict['task_description'],\n","                           \"analysis\": chat_env.env_dict['analysis'],\n","                           \"faculty\": chat_env.env_dict['faculty'],\n","                           \"student\": chat_env.env_dict['student']})\n","\n","\n","\n","  def update_chat_env():\n","        if len(self.seminar_conclusion) > 0:\n","            chat_env.env_dict['dean'] = self.seminar_conclusion.split(\"<INFO>\")[-1].lower().replace(\".\", \"\").strip()\n","        return chat_env"],"metadata":{"id":"BRLf65RLuDt-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Review():\n","  def __init__(self, **kwargs):\n","        super().__init__(**kwargs)\n","\n","  def update_phase_env():\n","    self.phase_env.update({\"task\": chat_env.env_dict['task_prompt'],\n","                           \"description\": chat_env.env_dict['task_description'],\n","                           \"analysis\": chat_env.env_dict['analysis'],\n","                           \"faculty\": chat_env.env_dict['faculty'],\n","                           \"student\": chat_env.env_dict['student'],\n","                           \"dean\": chat_env.env_dict['dean']})\n","\n","  def update_chat_env():\n","        if len(self.seminar_conclusion) > 0:\n","            chat_env.env_dict['final'] = self.seminar_conclusion.split(\"<INFO>\")[-1].lower().replace(\".\", \"\").strip()\n","        return chat_env"],"metadata":{"id":"eNQV6IZYuH8U"},"execution_count":null,"outputs":[]}]}